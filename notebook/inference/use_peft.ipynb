{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84ad7c8-0720-4db6-9f30-9d9c1510cfab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a9d2f8-6676-4bac-b3e8-7da1cc9dfc44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.0\n",
      "CUDA SETUP: Detected CUDA version 120\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda120_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('America/Los_Angeles')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"pythainlp/adapter-xglm-7.5B-alpaca\"\n",
    "base_model_name_or_path=\"facebook/xglm-7.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854d4a71-e5bb-4f9d-b480-568f63c75d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0e239fa7b5444fa2e39d12d2c29b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a46753f95f4dcfa77e53f69be5475d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/15.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6beca5e43454da0a432761d25704aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07c7dc7c5454ce299b7c06aff4b6bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b7f4afb854fbd9c504468c1fa0846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/4.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf821b90c8e43bc9dd298c4bd958a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68994ac016e7482da876bb07bb3b1109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/276 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4921a61022ce41779c6e45cf24ea7144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/adapter_config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2255e92c3d47b8b56f06bab6694913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading adapter_model.bin:   0%|          | 0.00/67.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name_or_path, return_dict=True, load_in_8bit=False, device_map=\"auto\",torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8248e79a-a4de-4e1b-9ccd-f58e3d109b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: Evaluate the following statement \" The world is better now compared to 10 years ago.\" <bot>: 5/5\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: Evaluate the following statement \" The world is better now compared to 10 years ago.\" <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa715ef8-6aba-4a8f-bda1-ab1ca5acfce6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     2,   1131,  54987,   1128,     13, 140821,     90,     32,  12894,\n",
       "          39730,     57,    268,   3038,     67,   4799,   1920,  67459,     33,\n",
       "            209,   2432,   1939,   1406,   1131,   9932,   1128,     13,      6]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae90cea1-17ff-4c25-8c91-48aad6f396bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: แนะนําวิธีลดน้ําหนักให้หน่อย <bot>: ลดน้ําหนักให้ได้ผล ควรออกกําลังกายอย่างสม่ําเสมอ ควบคุมอาหาร และพักผ่อนให้เพียงพอ หลีกเลี่ยงอาหารที่มีไขมันสูง และควรดื่มน้ําอย่างน้อยวันละ 8-10 แก้ว เพื่อช่วยขับของเสียออกจากร่างกาย และควรหลีกเลี่ยงเครื่องดื่มแอลกอฮอล์และบุหรี่ เพราะจะยิ่งทําให้อ้วนมากขึ้น\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: แนะนำวิธีลดน้ำหนักให้หน่อย <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c58bfcd-c4e1-480c-9d65-5e85d464d48a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Use Thai language only <human>: แนะนําวิธีลดน้ําหนักให้หน่อย <bot>: คําแนะนําในการลดน้ําหนักคือ รับประทานอาหารที่มีประโยชน์ ออกกําลังกายอย่างสม่ําเสมอ และควบคุมปริมาณแคลอรี่ที่ได้รับในแต่ละวัน นอกจากนี้ควรหลีกเลี่ยงอาหารที่มีไขมันสูงและอาหารที่มีน้ําตาลสูงด้วย\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('Use Thai language only\\n<human>: แนะนำวิธีลดน้ำหนักให้หน่อย <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d011204-9f7b-44c5-9ef2-348b6864d04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Use Thai language only without english <human>: อยากทําวิจัย ทําหัวข้ออะไรดี <bot>: การทําวิจัยในหัวข้อใดหัวข้อหนึ่ง ควรคํานึงถึงประเด็นหลักๆ ดังนี้ คือ หัวข้อวิจัยต้องมีความเกี่ยวข้องกับปัญหาหรือประเด็นที่สนใจ หัวข้อวิจัยต้องมีความเป็นไปได้ในการนําไปใช้ประโยชน์ หัวข้อวิจัยต้องมีความชัดเจนและครอบคลุมเนื้อหาที่สนใจ หัวข้อวิจัยต้องมีความเป็นไปได้ในการนําไปประยุกต์ใช้ และหัวข้อวิจัยต้องมีความน่าสนใจและดึงดูดใจผู้อ่าน\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('Use Thai language only without english\\n<human>: อยากทำวิจัย ทำหัวข้ออะไรดี <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4e0dfd-07db-4e0c-b8a4-8756527429d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: อยากทําวิจัย ทําหัวข้ออะไรดี <bot>: การทําวิจัยในหัวข้อ \"ปัจจัยที่มีผลต่อการตัดสินใจซื้อของผู้บริโภค\" น่าจะเป็นประโยชน์ต่อผู้วิจัย เพราะจะช่วยให้ผู้วิจัยเข้าใจถึงปัจจัยที่มีผลต่อการตัดสินใจซื้อของผู้บริโภค รวมถึงสามารถนําข้อมูลที่ได้ไปประยุกต์ใช้ให้เกิดประโยชน์ต่อธุรกิจได้\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: อยากทำวิจัย ทำหัวข้ออะไรดี <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58cd309f-05f8-4732-a316-4781c93c28f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Use Thai language only <human>: ขอวิธีจีบผู้หญิงให้หน่อย <bot>: เริ่มต้นด้วยการทําความรู้จักกับเธอก่อน ชวนเธอไปทานข้าว ดูหนัง หรือกิจกรรมอื่นๆ ด้วยกัน ค่อยๆ พูดคุยและทําความรู้จักกันมากขึ้น ค่อยๆ พัฒนาความสัมพันธ์ไปทีละนิด รับรองว่าเธอจะต้องตกหลุมรักคุณอย่างแน่นอน\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('Use Thai language only\\n<human>: ขอวิธีจีบผู้หญิงให้หน่อย <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86ec2b1-4415-45fe-b1ed-85576b9445f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: ขอวิธีจีบผู้หญิงให้หน่อย <bot>: เริ่มต้นจากการทําความรู้จักและพูดคุยกับเธออย่างเป็นกันเอง ชวนเธอไปทานข้าวหรือดูหนังด้วยกัน ชวนเธอไปเที่ยวหรือทํากิจกรรมต่างๆ ด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวนเธอไปออกเดทหรือไปเที่ยวด้วยกัน ชวน\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: ขอวิธีจีบผู้หญิงให้หน่อย <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad4e8eb-01b9-4039-aa25-2848e7ef5643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: อยากรู้ว่า ทําไมความฉลาดของมนุษย์เราไม่เท่ากัน <bot>: สาเหตุที่ความฉลาดของมนุษย์เราไม่เท่ากัน เนื่องมาจากพันธุกรรมและสิ่งแวดล้อมที่แตกต่างกัน บางคนอาจมีความฉลาดมากกว่าคนอื่น ๆ เนื่องมาจากพันธุกรรมที่ส่งผลให้มีความสามารถในการเรียนรู้และจดจําได้ดีกว่าคนอื่น ๆ ในขณะที่บางคนอาจมีความฉลาดน้อยกว่าคนอื่น ๆ เนื่องมาจากสิ่งแวดล้อมที่ส่งผลให้มีความสามารถในการเรียนรู้และจดจําได้น้อยกว่าคนอื่น ๆ\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: อยากรู้ว่า ทำไมความฉลาดของมนุษย์เราไม่เท่ากัน <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=124)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b522ed49-39c3-43a7-8a74-763f7dd9e560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: ทําไมการตัดคําภาษาไทยมันยากจัง <bot>: สาเหตุที่การตัดคําภาษาไทยมันยากนั้น เนื่องมาจากภาษาไทยมีสระและวรรณยุกต์จํานวนมาก ทําให้การตัดคําภาษาไทยนั้นยากกว่าภาษาอื่น ๆ มาก อีกทั้งยังมีคําศัพท์เฉพาะทางที่ต้องใช้ทักษะในการตัดคําสูงมากอีกด้วย\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: ทำไมการตัดคำภาษาไทยมันยากจัง\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=1024)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ff32e68-b76d-4c12-959b-dcee34d959c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: คิดอย่างไรกับกระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน ทั้ง ๆ ที่คณะทํางานเขาไม่มีใครเคยทําเอไอมาก่อน <bot>: กระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน เป็นเรื่องที่ค่อนข้างน่ากังวล เพราะอาจส่งผลกระทบต่อการพัฒนาเทคโนโลยีปัญญาประดิษฐ์ในอนาคตได้ หากกฎหมายดังกล่าวถูกผลักดันออกมาจริง จะทําให้เอไอถูกควบคุมและจํากัดการใช้อย่างเข้มงวด ซึ่งอาจส่งผลกระทบต่อการพัฒนาเทคโนโลยีปัญญาประดิษฐ์ในอนาคตได้\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: คิดอย่างไรกับกระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน ทั้ง ๆ ที่คณะทำงานเขาไม่มีใครเคยทำเอไอมาก่อน\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=1024)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d353495-9e51-405c-af4b-08bb611cdcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: คิดอย่างไรกับกระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน <bot>: กระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน เป็นเรื่องที่ควรพิจารณาอย่างรอบคอบ เนื่องจากกฎหมายจริยธรรมปัญญาประดิษฐ์เป็นกฎหมายที่มุ่งคุ้มครองสิทธิและเสรีภาพของประชาชนในการใช้เทคโนโลยีปัญญาประดิษฐ์อย่างเหมาะสม กฎหมายดังกล่าวจึงควรคํานึงถึงสิทธิและเสรีภาพของประชาชนเป็นหลัก โดยควรคํานึงถึงการคุ้มครองสิทธิและเสรีภาพขั้นพื้นฐานของประชาชน เช่น สิทธิในการรับรู้ข้อมูลข่าวสาร สิทธิในการเข้าถึงข้อมูล สิทธิในการแสดงความคิดเห็น สิทธิในการได้รับการคุ้มครองจากการใช้เทคโนโลยีปัญญาประดิษฐ์อย่างเหมาะสม สิทธิในการเข้าถึงข้อมูลและความเป็นส่วนตัว สิทธิในการเข้าถึงข้อมูลการรักษาพยาบาล เป็นต้น\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: คิดอย่างไรกับกระแสเรียกร้องกฎหมายจริยธรรมปัญญาประดิษฐ์ที่คนไทยบางกลุ่มผลักดัน\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=1024)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830992e7-60bc-474b-8845-b5fd2b9941be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: pythainlp คืออะไร <bot>: PYTHAINLP คือ ภาษาโปรแกรมเชิงวัตถุ (Object-Oriented Programming Language) ที่ถูกพัฒนาขึ้นโดยกลุ่มนักวิจัยจากมหาวิทยาลัยสแตนฟอร์ด PYTHAINLP ถูกออกแบบมาเพื่อใช้ในการเขียนโปรแกรมเชิงวัตถุโดยเฉพาะ PYTHAINLP มีลักษณะเด่นคือ การใช้ภาษาเชิงวัตถุในการเขียนโปรแกรม ทําให้สามารถเขียนโปรแกรมได้ง่ายขึ้น มีประสิทธิภาพมากขึ้น และมีความยืดหยุ่นสูง PYTHAINLP จึงเป็นภาษาโปรแกรมเชิงวัตถุที่ได้รับความนิยมอย่างมากในปัจจุบัน\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: pythainlp คืออะไร\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=1024)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d9508cf-eb3b-4f60-a6a5-843388a8829f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: \"หนังสือเรียนรายวิชาพื้นฐาน ภูมิศาสตร์ ม.1 ภูมิศาสตร์ (geography) คือ วิชาที่ศึกษาลักษณะของพื้นผิวโลกและผลที่เกิดขึ้นกับมนุษย์ โดยศึกษาเกี่ยวกับที่ตั้ง ความสัมพันธ์ระหว่างมนุษย์กับสิ่งแวดล้อม, การดําเนินชีวิตของมนุษย์ รวมทั้งเทคนิคทางภูมิศาสตร์ในการศึกษาและคาดการณ์ปรากฏการณ์ที่จะเกิดในอนาคต การศึกษา วิชาภูมิศาสตร์จําเป็นต้องทําความรู้จัก เข้าใจเครื่องมือทางภูมิศาสตร์ต่าง ๆ เช่น แผนที่ รูปถ่ายทางอากาศ ภาพจากดาวเทียม ตารางสถิติ กราฟ แผนภูมิ แผนภาพ 1. แผนที่ แผนที่ (map) คือ สิ่งที่มนุษย์สร้างขึ้นเพื่อแสดงลักษณะของพื้นผิวโลกและสิ่งต่าง ๆ บน พื้นผิวโลก ทั้งสิ่งที่เกิดขึ้นเองตามธรรมชาติและที่มนุษย์สร้างขึ้น โดยแสดงข้อมูลลงบนวัสดุ แบนราบ ด้วยการย่อขนาดให้เล็กลงตามมาตราส่วนที่ต้องการ โดยใช้สีและสัญลักษณ์แทนสิ่งที่มี อยู่จริงบนพื้นผิวโลกลงในแผนที่ แผนที่เป็นเครื่องมือทางภูมิศาสตร์ที่ จําเป็นต่อการศึกษาวิชาภูมิศาสตร์มาก เพราะการศึกษาวิชานี้ต้องกล่าวถึงสถานที่ ต่าง ๆ บนพื้นผิวโลกเสมอ ถ้ารู้จักชื่อ สถานที่แต่ไม่เคยไปสถานที่นั้นมาก่อน อาจนึกภาพไม่ออกว่าสถานที่นั้นตั้งอยู่ที่ไหน มีลักษณะทางกายภาพเป็นอย่างไร แผนที่ ช่วยบอกตําแหน่งที่ตั้งและลักษณะทาง กายภาพของสถานที่นั้นได้ เราใช้แผนที่เพื่อการท่องเที่ยวหรือวิเคราะห์ข้อมูล ทางภูมิศาสตร์ 1.1 การ กใช้แผนที่ ในการศึกษาข้อมูลทางภูมิศาสตร์ด้วยแผนที่ เราสามารถศึกษาข้อมูลแต่ละเรื่องได้จากแผนที่ เฉพาะเรื่อง (thematic map) เช่น แผนที่ท่องเที่ยว ถ้าเราต้องการ ศึกษาข้อมูลของทวีปเอเชีย ทวีปออสเตรเลีย และโอเชียเนีย เราเลือกใช้แผนที่เฉพาะเรื่องที่ต้องการ ศึกษาได้ด้วยการอ่านสัญลักษณ์และสีในแผนที่ เช่น 1) การใช้แผนที่รัฐกิจ (political map) เป็นแผนที่แสดงอาณาเขตการ ปกครอง เช่น เขตของจังหวัดหรือประเทศ และอาจแสดงข้อมูลอาณาเขตติดต่อกับดินแดนของ ประเทศหรือรัฐอื่น รวมทั้งที่ตั้งและชื่อของเมืองหลวง เมืองท่า หรือเมืองสําคัญอื่น ๆ บางฉบับ อาจแสดงลักษณะภูมิประเทศที่สําคัญประกอบด้วย แต่ไม่กําหนดความสูง สามารถใช้แผนที่ รัฐกิจในการบอกและวิเคราะห์ข้อมูลได้ ดังนี้ ลูกโลก แผนที่รัฐกิจ แผนที่ภูมิอากาศ แผนที่รัฐกิจ\" จากข้อความต่อไปนี้อะไรคือแผนที่รัฐกิจ? <bot>: แผนที่รัฐกิจ คือ แผนที่แสดงอาณาเขตการปกครอง เช่น เขตของจังหวัดหรือประเทศ และอาจแสดงข้อมูลอาณาเขตติดต่อกับดินแดนของ ประเทศหรือรัฐอื่น รวมทั้งที่ตั้งและชื่อของเมืองหลวง เมืองท่า หรือเมืองสําคัญอื่น ๆ บางฉบับ อาจแสดงลักษณะภูมิประเทศที่สําคัญประกอบด้วย แต่ไม่กําหนดความสูง สามารถใช้แผนที่รัฐกิจในการบอกและวิเคราะห์ข้อมูลได้ ดังนี้\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: \"หนังสือเรียนรายวิชาพื้นฐาน ภูมิศาสตร์ ม.1 ภูมิศาสตร์ (geography) คือ วิชาที่ศึกษาลักษณะของพื้นผิวโลกและผลที่เกิดขึ้นกับมนุษย์ โดยศึกษาเกี่ยวกับที่ตั้ง ความสัมพันธ์ระหว่างมนุษย์กับสิ่งแวดล้อม, การดำเนินชีวิตของมนุษย์ รวมทั้งเทคนิคทางภูมิศาสตร์ในการศึกษาและคาดการณ์ปรากฏการณ์ที่จะเกิดในอนาคต การศึกษา วิชาภูมิศาสตร์จำเป็นต้องทำความรู้จัก เข้าใจเครื่องมือทางภูมิศาสตร์ต่าง ๆ เช่น แผนที่ รูปถ่ายทางอากาศ ภาพจากดาวเทียม ตารางสถิติ กราฟ แผนภูมิ แผนภาพ 1. แผนที่ แผนที่ (map) คือ สิ่งที่มนุษย์สร้างขึ้นเพื่อแสดงลักษณะของพื้นผิวโลกและสิ่งต่าง ๆ บน พื้นผิวโลก ทั้งสิ่งที่เกิดขึ้นเองตามธรรมชาติและที่มนุษย์สร้างขึ้น โดยแสดงข้อมูลลงบนวัสดุ แบนราบ ด้วยการย่อขนาดให้เล็กลงตามมาตราส่วนที่ต้องการ โดยใช้สีและสัญลักษณ์แทนสิ่งที่มี อยู่จริงบนพื้นผิวโลกลงในแผนที่ แผนที่เป็นเครื่องมือทางภูมิศาสตร์ที่ จำเป็นต่อการศึกษาวิชาภูมิศาสตร์มาก เพราะการศึกษาวิชานี้ต้องกล่าวถึงสถานที่ ต่าง ๆ บนพื้นผิวโลกเสมอ ถ้ารู้จักชื่อ สถานที่แต่ไม่เคยไปสถานที่นั้นมาก่อน อาจนึกภาพไม่ออกว่าสถานที่นั้นตั้งอยู่ที่ไหน มีลักษณะทางกายภาพเป็นอย่างไร แผนที่ ช่วยบอกตำแหน่งที่ตั้งและลักษณะทาง กายภาพของสถานที่นั้นได้ เราใช้แผนที่เพื่อการท่องเที่ยวหรือวิเคราะห์ข้อมูล ทางภูมิศาสตร์ 1.1 การ กใช้แผนที่ ในการศึกษาข้อมูลทางภูมิศาสตร์ด้วยแผนที่ เราสามารถศึกษาข้อมูลแต่ละเรื่องได้จากแผนที่ เฉพาะเรื่อง (thematic map) เช่น แผนที่ท่องเที่ยว ถ้าเราต้องการ ศึกษาข้อมูลของทวีปเอเชีย ทวีปออสเตรเลีย และโอเชียเนีย เราเลือกใช้แผนที่เฉพาะเรื่องที่ต้องการ ศึกษาได้ด้วยการอ่านสัญลักษณ์และสีในแผนที่ เช่น 1) การใช้แผนที่รัฐกิจ (political map) เป็นแผนที่แสดงอาณาเขตการ ปกครอง เช่น เขตของจังหวัดหรือประเทศ และอาจแสดงข้อมูลอาณาเขตติดต่อกับดินแดนของ ประเทศหรือรัฐอื่น รวมทั้งที่ตั้งและชื่อของเมืองหลวง เมืองท่า หรือเมืองสำคัญอื่น ๆ บางฉบับ อาจแสดงลักษณะภูมิประเทศที่สำคัญประกอบด้วย แต่ไม่กำหนดความสูง สามารถใช้แผนที่ รัฐกิจในการบอกและวิเคราะห์ข้อมูลได้ ดังนี้ ลูกโลก แผนที่รัฐกิจ แผนที่ภูมิอากาศ แผนที่รัฐกิจ\" จากข้อความต่อไปนี้อะไรคือแผนที่รัฐกิจ?\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=5000)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cabd0358-b675-459a-b054-3356e8b6341e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: สมมติ แมว=1 คน=2 หมา=3 แล้ว แมว|คน|หมา=1|2|3 และ หมา|หมา=3|3 |a=2|1 แมว|หมา=1|3 โดยโจทย์นี้ไม่ใช่การคํานวณคณิตศาสตร์ แต่เป็นการเรียงอันดับตัวอักษร จงหาว่า แมว|คน เท่ากับเท่าไร <bot>: คําตอบคือ แมว|คน = 1 แมว|หมา = 2 หมา|หมา = 3\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: สมมติ แมว=1 คน=2 หมา=3 แล้ว แมว|คน|หมา=1|2|3 และ หมา|หมา=3|3 |a=2|1 แมว|หมา=1|3 โดยโจทย์นี้ไม่ใช่การคำนวณคณิตศาสตร์ แต่เป็นการเรียงอันดับตัวอักษร จงหาว่า แมว|คน เท่ากับเท่าไร\\n <bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b866232-028a-4aab-91d0-b40814e74ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: สมมติ a=1 b=2 c=3 แล้ว a b c=\"1 2 3\" และ c c=\"3 3\" b a=\"2 1\" a c=\"1 3\" จงหาว่า a b เท่ากับเท่าไร <bot>: คําตอบคือ a b = 3\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: สมมติ a=1 b=2 c=3 แล้ว a b c=\"1 2 3\" และ c c=\"3 3\" b a=\"2 1\" a c=\"1 3\" จงหาว่า a b เท่ากับเท่าไร\\n<bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7714de18-9686-4589-a339-14e9ca856190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: มะนาว:ลูก ช้าง:เชือก มนุษย์:คน มือถือ: <bot>: ช้าง: 1 เชือก มะนาว: 1 ลูก มนุษย์: 1 คน มือถือ: 1 เครื่อง\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: มะนาว:ลูก ช้าง:เชือก มนุษย์:คน มือถือ:\\n<bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5b8531e-c06f-4b03-8cbc-d275bc477df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: \"I play\" is translated into Thai as <bot>:                                                                                                                                                                                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: \"I play\" is translated into Thai as\\n<bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24938c33-e220-43a7-8e3a-88ee4a193dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: \"I play\" แปลป็นภาษาไทยภาษาทางการได้ <bot>: ดิฉันเล่น\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: \"I play\" แปลป็นภาษาไทยภาษาทางการได้\\n<bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aecc5ec8-94fc-4d40-a3c7-278ef8f9e5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <human>: \"I play\" แปลป็นภาษาไทยได้ <bot>: ดิฉันเล่น\n"
     ]
    }
   ],
   "source": [
    "batch = tokenizer('<human>: \"I play\" แปลป็นภาษาไทยได้\\n<bot>: ', return_tensors=\"pt\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(input_ids=batch[\"input_ids\"], max_new_tokens=520)\n",
    "\n",
    "print(\"\\n\\n\", tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a27213-af5d-4fd7-ac4c-b81127bf94b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
